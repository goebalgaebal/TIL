{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential() # 하나의 신경망, 층을 추가해서 사용하면 된다\n",
    "# 층 추가\n",
    "network.add(layers.Dense(512, # 계층의 출력개수\n",
    "                         activation=\"relu\", # 활성화 함수\n",
    "                         input_shape=(28*28, )))  # 입력 데이터 형태, 개수\n",
    "network.add(layers.Dense(10, # 계층의 출력개수\n",
    "                         activation=\"softmax\")) # 활성화 함수\n",
    "# 입력 데이터 형태는 첫번째만 입력하면 나머지 층은 알아서 계산해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 = 컴파일 과정\n",
    "# cost 손실 함수 정의\n",
    "network.compile(loss=\"categorical_crossentropy\", \n",
    "                optimizer=\"rmsprop\", \n",
    "                metrics=[\"accuracy\"]) # 중요하게 생각하는 척도, 여러개를 줄 수 있으므로 list로 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화\n",
    "cost를 최소화하는 방향으로 패러미터를 업데이트하는 것 <br><br>\n",
    "\n",
    "1. 경사하강법 SGD <br>\n",
    "기울기 * 학습률(lr) → 가중치 갱신 <br>\n",
    "단: 기울어진 방향으로만 이동, 복잡한 모델이라면 시간이 많이 걸린다 <br><br>\n",
    "\n",
    "2. 모멘텀\n",
    "운동량 <br>\n",
    "속도가 크면 기울기를 크게 업데이트 <br><br>\n",
    "\n",
    "3. AdaGrad RMSProp <br>\n",
    "학습률을 동일하게 주지말자. 상황(그래프의 기울기)에 따라 학습률을 다르게 주자 <br>\n",
    "새로운 기울기만 학습률에 반영<br><br>\n",
    "\n",
    "4. AdamGradient(모멘텀 + AdaGrad) <br>\n",
    "보통의 경우에 성능이 제일 좋다 <br><br>\n",
    "\n",
    "비교 논문 찾아볼 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape # test_images.shape\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\")/255 # 정규화\n",
    "\n",
    "test_images.shape # (10000, 28, 28)\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype(\"float32\")/255 # 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels # ay([5, 0, 4, ..., 5, 6, 8], dtype=uint8)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "print(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 12:50:32.576805 16220 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0807 12:50:32.630691 16220 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2552 - acc: 0.9268\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1036 - acc: 0.9692\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0681 - acc: 0.9793\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0500 - acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0376 - acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2078b91aa90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/step\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "test_cost, test_acc=network.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTk KoNLPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "# 사용 시, \n",
    "# jdk 버전 7이상 필요\n",
    "# JPype 설치 필요 - python 버전 맞춰서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'are', 'you', '?']\n",
      "['Do', \"n't\", 'touch', 'me']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(\"How are you?\"))\n",
    "print(word_tokenize(\"Don't touch me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', \"'\", 't', 'touch', 'me']\n"
     ]
    }
   ],
   "source": [
    "print(WordPunctTokenizer().tokenize(\"Don't touch me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아버지', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('가방', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('들어가신다', 'Verb')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "okt.pos(\"아버지가 가방에 들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Don', 'Alpha'),\n",
       " (\"'\", 'Punctuation'),\n",
       " ('t', 'Alpha'),\n",
       " ('touch', 'Alpha'),\n",
       " ('me', 'Alpha')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(\"Don't touch me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[('롯데마트', 'ncn'), ('의', 'jcm')], [('롯데마트의', 'ncn')], [('롯데마트', 'nqq'), ('의', 'jcm')], [('롯데마트의', 'nqq')]], [[('흑마늘', 'ncn')], [('흑마늘', 'nqq')]], [[('양념', 'ncn')]], [[('치킨', 'ncn'), ('이', 'jcc')], [('치킨', 'ncn'), ('이', 'jcs')], [('치킨', 'ncn'), ('이', 'ncn')]], [[('논란', 'ncpa'), ('이', 'jcc')], [('논란', 'ncpa'), ('이', 'jcs')], [('논란', 'ncpa'), ('이', 'ncn')]], [[('되', 'nbu'), ('고', 'jcj')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecc')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecs')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecx')], [('되', 'paa'), ('고', 'ecc')], [('되', 'paa'), ('고', 'ecs')], [('되', 'paa'), ('고', 'ecx')], [('되', 'pvg'), ('고', 'ecc')], [('되', 'pvg'), ('고', 'ecs')], [('되', 'pvg'), ('고', 'ecx')], [('되', 'px'), ('고', 'ecc')], [('되', 'px'), ('고', 'ecs')], [('되', 'px'), ('고', 'ecx')]], [[('있', 'paa'), ('다', 'ef')], [('있', 'px'), ('다', 'ef')]], [[('.', 'sf')], [('.', 'sy')]]]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "print(hannanum.analyze(\"롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is an interpreted, high-level, general-purpose programming language.', \"Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\", 'Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.', '[27] Python is dynamically typed and garbage-collected.', 'It supports multiple programming paradigms, including procedural, object-oriented, and functional programming.', 'Python is often described as a \"batteries included\" language due to its comprehensive standard library.', '[28]']\n",
      "====================================================================================================\n",
      "['Python', 'is', 'an', 'interpreted', ',', 'high-level', ',', 'general-purpose', 'programming', 'language', '.', 'Created', 'by', 'Guido', 'van', 'Rossum', 'and', 'first', 'released', 'in', '1991', ',', 'Python', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'of', 'significant', 'whitespace', '.', 'Its', 'language', 'constructs', 'and', 'object-oriented', 'approach', 'aim', 'to', 'help', 'programmers', 'write', 'clear', ',', 'logical', 'code', 'for', 'small', 'and', 'large-scale', 'projects', '.', '[', '27', ']', 'Python', 'is', 'dynamically', 'typed', 'and', 'garbage-collected', '.', 'It', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'and', 'functional', 'programming', '.', 'Python', 'is', 'often', 'described', 'as', 'a', '``', 'batteries', 'included', \"''\", 'language', 'due', 'to', 'its', 'comprehensive', 'standard', 'library', '.', '[', '28', ']']\n",
      "====================================================================================================\n",
      "[('Python', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('interpreted', 'JJ'), (',', ','), ('high-level', 'JJ'), (',', ','), ('general-purpose', 'JJ'), ('programming', 'NN'), ('language', 'NN'), ('.', '.'), ('Created', 'VBN'), ('by', 'IN'), ('Guido', 'NNP'), ('van', 'NN'), ('Rossum', 'NNP'), ('and', 'CC'), ('first', 'RB'), ('released', 'VBN'), ('in', 'IN'), ('1991', 'CD'), (',', ','), ('Python', 'NNP'), (\"'s\", 'POS'), ('design', 'NN'), ('philosophy', 'NN'), ('emphasizes', 'VBZ'), ('code', 'JJ'), ('readability', 'NN'), ('with', 'IN'), ('its', 'PRP$'), ('notable', 'JJ'), ('use', 'NN'), ('of', 'IN'), ('significant', 'JJ'), ('whitespace', 'NN'), ('.', '.'), ('Its', 'PRP$'), ('language', 'NN'), ('constructs', 'NNS'), ('and', 'CC'), ('object-oriented', 'JJ'), ('approach', 'NN'), ('aim', 'NN'), ('to', 'TO'), ('help', 'VB'), ('programmers', 'NNS'), ('write', 'VB'), ('clear', 'JJ'), (',', ','), ('logical', 'JJ'), ('code', 'NN'), ('for', 'IN'), ('small', 'JJ'), ('and', 'CC'), ('large-scale', 'JJ'), ('projects', 'NNS'), ('.', '.'), ('[', '$'), ('27', 'CD'), (']', 'NNP'), ('Python', 'NNP'), ('is', 'VBZ'), ('dynamically', 'RB'), ('typed', 'JJ'), ('and', 'CC'), ('garbage-collected', 'JJ'), ('.', '.'), ('It', 'PRP'), ('supports', 'VBZ'), ('multiple', 'JJ'), ('programming', 'NN'), ('paradigms', 'NN'), (',', ','), ('including', 'VBG'), ('procedural', 'JJ'), (',', ','), ('object-oriented', 'JJ'), (',', ','), ('and', 'CC'), ('functional', 'JJ'), ('programming', 'NN'), ('.', '.'), ('Python', 'NNP'), ('is', 'VBZ'), ('often', 'RB'), ('described', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('``', '``'), ('batteries', 'NNS'), ('included', 'VBD'), (\"''\", \"''\"), ('language', 'NN'), ('due', 'JJ'), ('to', 'TO'), ('its', 'PRP$'), ('comprehensive', 'JJ'), ('standard', 'NN'), ('library', 'NN'), ('.', '.'), ('[', 'CC'), ('28', 'CD'), (']', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import *\n",
    "from nltk.tag import *\n",
    "text = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[27] Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \\\"batteries included\\\" language due to its comprehensive standard library.[28]\"\n",
    "print(sent_tokenize(text)) # .을 기준으로 분리됨\n",
    "print(\"=\"*100)\n",
    "print(word_tokenize(text))\n",
    "print(\"=\"*100)\n",
    "print(pos_tag(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '도', '지각', '하지', '않고', '열심히', '공부', '한', '여러분', ',', '이번', '주도', '힘냅시다', '.']\n",
      "['오늘', '도', '지각', '하', '지', '않', '고', '열심히', '공부', '하', 'ㄴ', '여러분', ',', '이번', '주도', '힘내', 'ㅂ시다', '.']\n",
      "====================================================================================================\n",
      "[('오늘', 'Noun'), ('도', 'Josa'), ('지각', 'Noun'), ('하지', 'Verb'), ('않고', 'Verb'), ('열심히', 'Adverb'), ('공부', 'Noun'), ('한', 'Josa'), ('여러분', 'Noun'), (',', 'Punctuation'), ('이번', 'Noun'), ('주도', 'Noun'), ('힘냅시다', 'Verb'), ('.', 'Punctuation')]\n",
      "[('오늘', 'NNG'), ('도', 'JX'), ('지각', 'NNG'), ('하', 'XSV'), ('지', 'ECD'), ('않', 'VXV'), ('고', 'ECE'), ('열심히', 'MAG'), ('공부', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('여러분', 'NP'), (',', 'SP'), ('이번', 'NNG'), ('주도', 'NNG'), ('힘내', 'VV'), ('ㅂ시다', 'EFA'), ('.', 'SF')]\n",
      "====================================================================================================\n",
      "['오늘', '지각', '공부', '여러분', '이번', '주도']\n",
      "['오늘', '지각', '공부', '여러분', '이번', '주도']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "print(okt.morphs(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번 주도 힘냅시다.\"))\n",
    "print(kkma.morphs(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번 주도 힘냅시다.\"))\n",
    "print(\"=\"*100)\n",
    "print(okt.pos(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번 주도 힘냅시다.\"))\n",
    "print(kkma.pos(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번 주도 힘냅시다.\"))\n",
    "print(\"=\"*100)\n",
    "print(okt.nouns(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번 주도 힘냅시다.\"))\n",
    "print(kkma.nouns(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번 주도 힘냅시다.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 대소문자 통합\n",
    "* 불용어 제거(대체)\n",
    "* 특수문자 처리\n",
    "* 시제/인칭 처리 <br>\n",
    "train, trining, trains, ... → train <br>\n",
    "are/ is/ was/ were → be <br>\n",
    "* 정규표현식\n",
    "* 형태소: 어간stem, 접사\n",
    "* 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have\n",
      "be\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "# 단어, 품사 → 동사의 원형 출력\n",
    "print(wnl.lemmatize(\"has\", \"v\")) \n",
    "print(wnl.lemmatize(\"were\", \"v\")) # 동의어 처리 시 편리\n",
    "print(wnl.lemmatize(\"be\", \"v\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어간 추출\n",
    "포터 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'an', 'interpreted', ',', 'high-level', ',', 'general-purpose', 'programming', 'language', '.', 'Created', 'by', 'Guido', 'van', 'Rossum', 'and', 'first', 'released', 'in', '1991', ',', 'Python', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'of', 'significant', 'whitespace', '.', 'Its', 'language', 'constructs', 'and', 'object-oriented', 'approach', 'aim', 'to', 'help', 'programmers', 'write', 'clear', ',', 'logical', 'code', 'for', 'small', 'and', 'large-scale', 'projects', '.', '[', '27', ']', 'Python', 'is', 'dynamically', 'typed', 'and', 'garbage-collected', '.', 'It', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'and', 'functional', 'programming', '.', 'Python', 'is', 'often', 'described', 'as', 'a', '``', 'batteries', 'included', \"''\", 'language', 'due', 'to', 'its', 'comprehensive', 'standard', 'library', '.', '[', '28', ']']\n",
      "====================================================================================================\n",
      "['python', 'is', 'an', 'interpret', ',', 'high-level', ',', 'general-purpos', 'program', 'languag', '.', 'creat', 'by', 'guido', 'van', 'rossum', 'and', 'first', 'releas', 'in', '1991', ',', 'python', \"'s\", 'design', 'philosophi', 'emphas', 'code', 'readabl', 'with', 'it', 'notabl', 'use', 'of', 'signific', 'whitespac', '.', 'it', 'languag', 'construct', 'and', 'object-ori', 'approach', 'aim', 'to', 'help', 'programm', 'write', 'clear', ',', 'logic', 'code', 'for', 'small', 'and', 'large-scal', 'project', '.', '[', '27', ']', 'python', 'is', 'dynam', 'type', 'and', 'garbage-collect', '.', 'It', 'support', 'multipl', 'program', 'paradigm', ',', 'includ', 'procedur', ',', 'object-ori', ',', 'and', 'function', 'program', '.', 'python', 'is', 'often', 'describ', 'as', 'a', '``', 'batteri', 'includ', \"''\", 'languag', 'due', 'to', 'it', 'comprehens', 'standard', 'librari', '.', '[', '28', ']']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "words = word_tokenize(text)\n",
    "print(words)\n",
    "print(\"=\"*100)\n",
    "ps_words = [ps.stem(w) for w in words]\n",
    "print(ps_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'need',\n",
       " 'you',\n",
       " 'to',\n",
       " 'help',\n",
       " 'me',\n",
       " '.',\n",
       " 'I',\n",
       " 'like',\n",
       " 'coding',\n",
       " '.',\n",
       " 'what',\n",
       " \"'s\",\n",
       " 'your',\n",
       " 'hobby',\n",
       " '.']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"I need you to help me. I like coding. what's your hobby.\"\n",
    "test = word_tokenize(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'need', 'help', '.', 'I', 'like', 'coding', '.', \"'s\", 'hobby', '.']\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for w in test:\n",
    "    if w not in sw:\n",
    "        res.append(w)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = \"하기싫어 싫거든 안해\"\n",
    "test = \"파이썬 코딩을 열심히 해야합니다. 하기 싫어도 해요. 그래도 싫거든 하세요. 안해 안해 안해\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['열심히', '하기싫어', '싫거든', '안해']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = sw.split(\" \")\n",
    "sw # 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['파이썬',\n",
       " '코딩을',\n",
       " '열심히',\n",
       " '해야합니다',\n",
       " '.',\n",
       " '하기',\n",
       " '싫어도',\n",
       " '해요',\n",
       " '.',\n",
       " '그래도',\n",
       " '싫거든',\n",
       " '하세요',\n",
       " '.',\n",
       " '안해',\n",
       " '안해',\n",
       " '안해']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = word_tokenize(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['파이썬', '코딩을', '열심히', '해야합니다', '.', '싫어도', '해요', '.', '그래도', '하세요', '.']\n"
     ]
    }
   ],
   "source": [
    "res2 = []\n",
    "for w in test:\n",
    "    if w not in sw:\n",
    "        res2.append(w)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[27] Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library.[28]'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 단어에 대한 등장 회수 출력 <br>\n",
    "단어 길이가 2이하인 경우 제외 <br>\n",
    "불용어 제거 <br>\n",
    "대소문자 구분 없음(모두 소문자로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'interpreted', 'high-level', 'general-purpose', 'programming', 'language', 'created', 'guido', 'van', 'rossum', 'first', 'released', '1991', 'python', 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'notable', 'use', 'significant', 'whitespace', 'its', 'language', 'constructs', 'object-oriented', 'approach', 'aim', 'help', 'programmers', 'write', 'clear', 'logical', 'code', 'small', 'large-scale', 'projects', 'python', 'dynamically', 'typed', 'garbage-collected', 'supports', 'multiple', 'programming', 'paradigms', 'including', 'procedural', 'object-oriented', 'functional', 'programming', 'python', 'often', 'described', 'batteries', 'included', 'language', 'due', 'comprehensive', 'standard', 'library']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석\n",
    "token_word = word_tokenize(text)\n",
    "\n",
    "# 불용어 제거\n",
    "sw = stopwords.words(\"english\")\n",
    "words = []\n",
    "for w in token_word:\n",
    "    if (w not in sw) & (len(str(w)) > 2): # 길이 2 이상\n",
    "        words.append(str(w).lower()) # 소문자 처리\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 4, 'interpreted': 1, 'high-level': 1, 'general-purpose': 1, 'programming': 3, 'language': 3, 'created': 1, 'guido': 1, 'van': 1, 'rossum': 1, 'first': 1, 'released': 1, '1991': 1, 'design': 1, 'philosophy': 1, 'emphasizes': 1, 'code': 2, 'readability': 1, 'notable': 1, 'use': 1, 'significant': 1, 'whitespace': 1, 'its': 1, 'constructs': 1, 'object-oriented': 2, 'approach': 1, 'aim': 1, 'help': 1, 'programmers': 1, 'write': 1, 'clear': 1, 'logical': 1, 'small': 1, 'large-scale': 1, 'projects': 1, 'dynamically': 1, 'typed': 1, 'garbage-collected': 1, 'supports': 1, 'multiple': 1, 'paradigms': 1, 'including': 1, 'procedural': 1, 'functional': 1, 'often': 1, 'described': 1, 'batteries': 1, 'included': 1, 'due': 1, 'comprehensive': 1, 'standard': 1, 'library': 1}\n"
     ]
    }
   ],
   "source": [
    "word_dic = {}\n",
    "for w in words:\n",
    "    if w not in word_dic.keys():\n",
    "        word_dic[w] = 1\n",
    "    else:\n",
    "        word_dic[w] += 1\n",
    "print(word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = word_dic.keys()\n",
    "count = word_dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interpreted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high-level</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general-purpose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>programming</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>created</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>guido</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rossum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>first</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>released</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>emphasizes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>code</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>readability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>notable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>use</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>significant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>whitespace</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>its</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>constructs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>object-oriented</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>approach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>help</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>programmers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>logical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>large-scale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>projects</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dynamically</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>typed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>garbage-collected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>supports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>multiple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>paradigms</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>including</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>procedural</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>functional</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>often</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>described</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>batteries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>included</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>due</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>comprehensive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>library</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  count\n",
       "0              python      4\n",
       "1         interpreted      1\n",
       "2          high-level      1\n",
       "3     general-purpose      1\n",
       "4         programming      3\n",
       "5            language      3\n",
       "6             created      1\n",
       "7               guido      1\n",
       "8                 van      1\n",
       "9              rossum      1\n",
       "10              first      1\n",
       "11           released      1\n",
       "12               1991      1\n",
       "13             design      1\n",
       "14         philosophy      1\n",
       "15         emphasizes      1\n",
       "16               code      2\n",
       "17        readability      1\n",
       "18            notable      1\n",
       "19                use      1\n",
       "20        significant      1\n",
       "21         whitespace      1\n",
       "22                its      1\n",
       "23         constructs      1\n",
       "24    object-oriented      2\n",
       "25           approach      1\n",
       "26                aim      1\n",
       "27               help      1\n",
       "28        programmers      1\n",
       "29              write      1\n",
       "30              clear      1\n",
       "31            logical      1\n",
       "32              small      1\n",
       "33        large-scale      1\n",
       "34           projects      1\n",
       "35        dynamically      1\n",
       "36              typed      1\n",
       "37  garbage-collected      1\n",
       "38           supports      1\n",
       "39           multiple      1\n",
       "40          paradigms      1\n",
       "41          including      1\n",
       "42         procedural      1\n",
       "43         functional      1\n",
       "44              often      1\n",
       "45          described      1\n",
       "46          batteries      1\n",
       "47           included      1\n",
       "48                due      1\n",
       "49      comprehensive      1\n",
       "50           standard      1\n",
       "51            library      1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"word\": list(word), \"count\": list(count)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['python', 'interpreted', 'high-level', 'general-purpose', 'programming', 'language'], ['created', 'guido', 'van', 'rossum', 'first', 'released', '1991', 'python', 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'notable', 'use', 'significant', 'whitespace'], ['language', 'constructs', 'object-oriented', 'approach', 'aim', 'help', 'programmers', 'write', 'clear', 'logical', 'code', 'small', 'large-scale', 'projects'], ['python', 'dynamically', 'typed', 'garbage-collected'], ['supports', 'multiple', 'programming', 'paradigms', 'including', 'procedural', 'object-oriented', 'functional', 'programming'], ['python', 'often', 'described', 'batteries', 'included', 'language', 'due', 'comprehensive', 'standard', 'library'], []]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "text = sent_tokenize(text)\n",
    "voc = Counter()\n",
    "sentences = []\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "for i in text:\n",
    "    sentence = word_tokenize(i)\n",
    "    res = []\n",
    "    for word in sentence:\n",
    "        word = word.lower()\n",
    "        if word not in stop_words:\n",
    "            if len(word) > 2:\n",
    "                res.append(word)\n",
    "                voc[word] = voc[word]+1\n",
    "    sentences.append(res)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x207d0200ac8>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMap = folium.Map(location=[37.5016475,127.0380273], \n",
    "                   zoom_start=16)\n",
    "                   #tiles=\"Stamen Toner\") # 지도 출력 스타일:Stamen Terrain, Stamen Toner\n",
    "folium.Marker([37.5016475,127.0380273], popup=\"멀티 캠퍼스\").add_to(myMap)                   \n",
    "myMap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
