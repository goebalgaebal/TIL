{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]]) \n",
    "# 중간 중간 데이터의 변화 값이 크다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata = xy[:, 0:-1]\n",
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "w = tf.Variable(tf.random_normal([4, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.matmul(x, w) + b\n",
    "cost = tf.reduce_mean(tf.square(hf-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.00001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 2466671200000.0 \n",
      "hf:\n",
      " [[1108463.8]\n",
      " [2231345.5]\n",
      " [1755340.9]\n",
      " [1230514.6]\n",
      " [1450210.5]\n",
      " [1462416.4]\n",
      " [1340363. ]\n",
      " [1706518.1]]\n",
      "1 cost: 2.7100838e+31 \n",
      "hf:\n",
      " [[-3.6721689e+15]\n",
      " [-7.3924526e+15]\n",
      " [-5.8153761e+15]\n",
      " [-4.0765473e+15]\n",
      " [-4.8044293e+15]\n",
      " [-4.8448670e+15]\n",
      " [-4.4404880e+15]\n",
      " [-5.6536244e+15]]\n",
      "2 cost: inf \n",
      "hf:\n",
      " [[1.2171901e+25]\n",
      " [2.4503285e+25]\n",
      " [1.9275850e+25]\n",
      " [1.3512269e+25]\n",
      " [1.5924930e+25]\n",
      " [1.6058968e+25]\n",
      " [1.4718599e+25]\n",
      " [1.8739703e+25]]\n",
      "3 cost: inf \n",
      "hf:\n",
      " [[-4.0345414e+34]\n",
      " [-8.1219458e+34]\n",
      " [-6.3892418e+34]\n",
      " [-4.4788245e+34]\n",
      " [-5.2785342e+34]\n",
      " [-5.3229624e+34]\n",
      " [-4.8786791e+34]\n",
      " [-6.2115281e+34]]\n",
      "4 cost: inf \n",
      "hf:\n",
      " [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "5 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "6 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 cost: nan \n",
      "hf:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(101):\n",
    "    cv, hv,_ = sess.run([cost, hf, train], feed_dict={x: xdata, y: ydata})\n",
    "    print(step, \"cost:\", cv, \"\\nhf:\\n\", hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyScaler(data): # MinMaxScaling\n",
    "    de = np.max(data, axis=0) - np.min(data, axis=0)# 열 단위 최소값 axis=0\n",
    "    num = data - np.min(data, axis=0)\n",
    "    return num/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.        , 1.        ],\n",
       "       [0.70548491, 0.70439552, 1.        , 0.71881783],\n",
       "       [0.54412549, 0.50274824, 0.57608696, 0.60646801],\n",
       "       [0.33890353, 0.31368023, 0.10869565, 0.45989134],\n",
       "       [0.51436   , 0.4258239 , 0.30434783, 0.58504805],\n",
       "       [0.49556179, 0.4258239 , 0.31521739, 0.48131134],\n",
       "       [0.11436064, 0.        , 0.20652174, 0.22007776],\n",
       "       [0.        , 0.07747099, 0.5326087 , 0.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata = MyScaler(xdata) # xdata에 대해서만 정규화, ydata도 정규화를 한다면 역정규화가 필요\n",
    "xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 672016.1 \n",
      "hf:\n",
      " [[0.8726529]\n",
      " [0.4585414]\n",
      " [0.7700491]\n",
      " [1.1650338]\n",
      " [0.9280863]\n",
      " [1.0605338]\n",
      " [1.2535166]\n",
      " [1.392415 ]]\n",
      "1 cost: 672011.25 \n",
      "hf:\n",
      " [[0.8766066 ]\n",
      " [0.462448  ]\n",
      " [0.77333015]\n",
      " [1.167609  ]\n",
      " [0.9311024 ]\n",
      " [1.0634553 ]\n",
      " [1.2555568 ]\n",
      " [1.3944421 ]]\n",
      "2 cost: 672006.4 \n",
      "hf:\n",
      " [[0.8805603 ]\n",
      " [0.4663546 ]\n",
      " [0.77661127]\n",
      " [1.1701841 ]\n",
      " [0.93411845]\n",
      " [1.0663768 ]\n",
      " [1.2575972 ]\n",
      " [1.396469  ]]\n",
      "3 cost: 672001.5 \n",
      "hf:\n",
      " [[0.884514  ]\n",
      " [0.47026122]\n",
      " [0.7798923 ]\n",
      " [1.1727593 ]\n",
      " [0.9371345 ]\n",
      " [1.0692983 ]\n",
      " [1.2596376 ]\n",
      " [1.3984959 ]]\n",
      "4 cost: 671996.7 \n",
      "hf:\n",
      " [[0.88846767]\n",
      " [0.47416782]\n",
      " [0.7831733 ]\n",
      " [1.1753343 ]\n",
      " [0.9401505 ]\n",
      " [1.0722197 ]\n",
      " [1.2616779 ]\n",
      " [1.4005228 ]]\n",
      "5 cost: 671991.8 \n",
      "hf:\n",
      " [[0.89242136]\n",
      " [0.47807443]\n",
      " [0.78645444]\n",
      " [1.1779094 ]\n",
      " [0.9431667 ]\n",
      " [1.0751412 ]\n",
      " [1.2637182 ]\n",
      " [1.4025497 ]]\n",
      "6 cost: 671986.94 \n",
      "hf:\n",
      " [[0.89637506]\n",
      " [0.48198104]\n",
      " [0.7897355 ]\n",
      " [1.1804845 ]\n",
      " [0.9461827 ]\n",
      " [1.0780628 ]\n",
      " [1.2657585 ]\n",
      " [1.4045768 ]]\n",
      "7 cost: 671982.0 \n",
      "hf:\n",
      " [[0.90032876]\n",
      " [0.48588753]\n",
      " [0.79301655]\n",
      " [1.1830596 ]\n",
      " [0.9491987 ]\n",
      " [1.0809844 ]\n",
      " [1.2677989 ]\n",
      " [1.4066037 ]]\n",
      "8 cost: 671977.25 \n",
      "hf:\n",
      " [[0.90428245]\n",
      " [0.48979414]\n",
      " [0.79629755]\n",
      " [1.1856346 ]\n",
      " [0.95221484]\n",
      " [1.0839058 ]\n",
      " [1.2698393 ]\n",
      " [1.4086306 ]]\n",
      "9 cost: 671972.3 \n",
      "hf:\n",
      " [[0.908236  ]\n",
      " [0.49370062]\n",
      " [0.79957855]\n",
      " [1.1882097 ]\n",
      " [0.9552307 ]\n",
      " [1.0868272 ]\n",
      " [1.2718794 ]\n",
      " [1.4106575 ]]\n",
      "10 cost: 671967.5 \n",
      "hf:\n",
      " [[0.9121896 ]\n",
      " [0.497607  ]\n",
      " [0.8028594 ]\n",
      " [1.1907847 ]\n",
      " [0.95824665]\n",
      " [1.0897485 ]\n",
      " [1.2739196 ]\n",
      " [1.4126843 ]]\n",
      "11 cost: 671962.56 \n",
      "hf:\n",
      " [[0.9161431]\n",
      " [0.5015135]\n",
      " [0.8061404]\n",
      " [1.1933596]\n",
      " [0.9612626]\n",
      " [1.09267  ]\n",
      " [1.2759598]\n",
      " [1.4147111]]\n",
      "12 cost: 671957.75 \n",
      "hf:\n",
      " [[0.9200967 ]\n",
      " [0.50541997]\n",
      " [0.8094213 ]\n",
      " [1.1959345 ]\n",
      " [0.96427846]\n",
      " [1.0955913 ]\n",
      " [1.2780001 ]\n",
      " [1.416738  ]]\n",
      "13 cost: 671952.8 \n",
      "hf:\n",
      " [[0.9240502 ]\n",
      " [0.50932646]\n",
      " [0.81270224]\n",
      " [1.1985096 ]\n",
      " [0.9672944 ]\n",
      " [1.0985126 ]\n",
      " [1.2800403 ]\n",
      " [1.4187648 ]]\n",
      "14 cost: 671948.0 \n",
      "hf:\n",
      " [[0.92800367]\n",
      " [0.5132327 ]\n",
      " [0.8159831 ]\n",
      " [1.2010845 ]\n",
      " [0.9703103 ]\n",
      " [1.101434  ]\n",
      " [1.2820804 ]\n",
      " [1.4207916 ]]\n",
      "15 cost: 671943.1 \n",
      "hf:\n",
      " [[0.93195707]\n",
      " [0.5171391 ]\n",
      " [0.81926394]\n",
      " [1.2036594 ]\n",
      " [0.9733261 ]\n",
      " [1.1043553 ]\n",
      " [1.2841206 ]\n",
      " [1.4228184 ]]\n",
      "16 cost: 671938.25 \n",
      "hf:\n",
      " [[0.9359105 ]\n",
      " [0.52104545]\n",
      " [0.8225448 ]\n",
      " [1.2062343 ]\n",
      " [0.97634196]\n",
      " [1.1072766 ]\n",
      " [1.2861608 ]\n",
      " [1.4248452 ]]\n",
      "17 cost: 671933.3 \n",
      "hf:\n",
      " [[0.9398639 ]\n",
      " [0.5249518 ]\n",
      " [0.8258256 ]\n",
      " [1.2088091 ]\n",
      " [0.97935784]\n",
      " [1.1101978 ]\n",
      " [1.288201  ]\n",
      " [1.4268721 ]]\n",
      "18 cost: 671928.5 \n",
      "hf:\n",
      " [[0.9438173 ]\n",
      " [0.5288582 ]\n",
      " [0.82910645]\n",
      " [1.211384  ]\n",
      " [0.9823737 ]\n",
      " [1.1131192 ]\n",
      " [1.2902411 ]\n",
      " [1.4288989 ]]\n",
      "19 cost: 671923.6 \n",
      "hf:\n",
      " [[0.9477708 ]\n",
      " [0.53276455]\n",
      " [0.8323873 ]\n",
      " [1.213959  ]\n",
      " [0.98538953]\n",
      " [1.1160405 ]\n",
      " [1.2922814 ]\n",
      " [1.4309258 ]]\n",
      "20 cost: 671918.75 \n",
      "hf:\n",
      " [[0.9517241 ]\n",
      " [0.5366708 ]\n",
      " [0.83566815]\n",
      " [1.2165339 ]\n",
      " [0.98840535]\n",
      " [1.1189618 ]\n",
      " [1.2943215 ]\n",
      " [1.4329526 ]]\n",
      "21 cost: 671913.9 \n",
      "hf:\n",
      " [[0.95567745]\n",
      " [0.5405772 ]\n",
      " [0.83894897]\n",
      " [1.2191088 ]\n",
      " [0.99142116]\n",
      " [1.121883  ]\n",
      " [1.2963617 ]\n",
      " [1.4349794 ]]\n",
      "22 cost: 671909.0 \n",
      "hf:\n",
      " [[0.9596308]\n",
      " [0.5444834]\n",
      " [0.8422297]\n",
      " [1.2216837]\n",
      " [0.994437 ]\n",
      " [1.1248043]\n",
      " [1.2984018]\n",
      " [1.4370062]]\n",
      "23 cost: 671904.1 \n",
      "hf:\n",
      " [[0.9635841 ]\n",
      " [0.5483898 ]\n",
      " [0.84551054]\n",
      " [1.2242587 ]\n",
      " [0.9974528 ]\n",
      " [1.1277256 ]\n",
      " [1.300442  ]\n",
      " [1.439033  ]]\n",
      "24 cost: 671899.25 \n",
      "hf:\n",
      " [[0.96753746]\n",
      " [0.55229604]\n",
      " [0.84879136]\n",
      " [1.2268335 ]\n",
      " [1.0004686 ]\n",
      " [1.130647  ]\n",
      " [1.3024821 ]\n",
      " [1.44106   ]]\n",
      "25 cost: 671894.4 \n",
      "hf:\n",
      " [[0.9714908]\n",
      " [0.5562024]\n",
      " [0.8520721]\n",
      " [1.2294084]\n",
      " [1.0034845]\n",
      " [1.1335682]\n",
      " [1.3045224]\n",
      " [1.4430867]]\n",
      "26 cost: 671889.5 \n",
      "hf:\n",
      " [[0.97544414]\n",
      " [0.56010854]\n",
      " [0.85535294]\n",
      " [1.2319833 ]\n",
      " [1.0065002 ]\n",
      " [1.1364894 ]\n",
      " [1.3065625 ]\n",
      " [1.4451135 ]]\n",
      "27 cost: 671884.6 \n",
      "hf:\n",
      " [[0.9793975 ]\n",
      " [0.5640148 ]\n",
      " [0.85863376]\n",
      " [1.2345581 ]\n",
      " [1.009516  ]\n",
      " [1.1394106 ]\n",
      " [1.3086027 ]\n",
      " [1.4471403 ]]\n",
      "28 cost: 671879.75 \n",
      "hf:\n",
      " [[0.98335075]\n",
      " [0.56792104]\n",
      " [0.8619145 ]\n",
      " [1.237133  ]\n",
      " [1.0125318 ]\n",
      " [1.1423318 ]\n",
      " [1.3106428 ]\n",
      " [1.4491671 ]]\n",
      "29 cost: 671874.94 \n",
      "hf:\n",
      " [[0.987304 ]\n",
      " [0.5718272]\n",
      " [0.8651951]\n",
      " [1.2397077]\n",
      " [1.0155475]\n",
      " [1.145253 ]\n",
      " [1.3126829]\n",
      " [1.4511938]]\n",
      "30 cost: 671870.06 \n",
      "hf:\n",
      " [[0.9912572 ]\n",
      " [0.5757332 ]\n",
      " [0.86847574]\n",
      " [1.2422825 ]\n",
      " [1.0185632 ]\n",
      " [1.148174  ]\n",
      " [1.314723  ]\n",
      " [1.4532205 ]]\n",
      "31 cost: 671865.1 \n",
      "hf:\n",
      " [[0.99521035]\n",
      " [0.5796393 ]\n",
      " [0.8717563 ]\n",
      " [1.2448573 ]\n",
      " [1.0215788 ]\n",
      " [1.1510953 ]\n",
      " [1.316763  ]\n",
      " [1.4552472 ]]\n",
      "32 cost: 671860.3 \n",
      "hf:\n",
      " [[0.99916357]\n",
      " [0.58354545]\n",
      " [0.87503695]\n",
      " [1.247432  ]\n",
      " [1.0245944 ]\n",
      " [1.1540163 ]\n",
      " [1.3188031 ]\n",
      " [1.4572738 ]]\n",
      "33 cost: 671855.5 \n",
      "hf:\n",
      " [[1.0031167 ]\n",
      " [0.5874516 ]\n",
      " [0.87831765]\n",
      " [1.2500068 ]\n",
      " [1.0276101 ]\n",
      " [1.1569375 ]\n",
      " [1.3208431 ]\n",
      " [1.4593005 ]]\n",
      "34 cost: 671850.6 \n",
      "hf:\n",
      " [[1.00707  ]\n",
      " [0.5913577]\n",
      " [0.8815983]\n",
      " [1.2525815]\n",
      " [1.0306258]\n",
      " [1.1598586]\n",
      " [1.3228831]\n",
      " [1.4613272]]\n",
      "35 cost: 671845.7 \n",
      "hf:\n",
      " [[1.011023 ]\n",
      " [0.5952637]\n",
      " [0.884879 ]\n",
      " [1.2551563]\n",
      " [1.0336415]\n",
      " [1.1627797]\n",
      " [1.3249232]\n",
      " [1.4633539]]\n",
      "36 cost: 671840.8 \n",
      "hf:\n",
      " [[1.0149763 ]\n",
      " [0.59916985]\n",
      " [0.8881595 ]\n",
      " [1.257731  ]\n",
      " [1.0366571 ]\n",
      " [1.1657008 ]\n",
      " [1.3269632 ]\n",
      " [1.4653805 ]]\n",
      "37 cost: 671836.0 \n",
      "hf:\n",
      " [[1.0189295 ]\n",
      " [0.60307586]\n",
      " [0.89144015]\n",
      " [1.2603058 ]\n",
      " [1.0396727 ]\n",
      " [1.1686219 ]\n",
      " [1.3290032 ]\n",
      " [1.4674072 ]]\n",
      "38 cost: 671831.1 \n",
      "hf:\n",
      " [[1.0228827]\n",
      " [0.606982 ]\n",
      " [0.8947208]\n",
      " [1.2628806]\n",
      " [1.0426884]\n",
      " [1.1715431]\n",
      " [1.3310432]\n",
      " [1.4694339]]\n",
      "39 cost: 671826.25 \n",
      "hf:\n",
      " [[1.0268358 ]\n",
      " [0.6108881 ]\n",
      " [0.89800143]\n",
      " [1.2654552 ]\n",
      " [1.0457041 ]\n",
      " [1.1744642 ]\n",
      " [1.3330834 ]\n",
      " [1.4714606 ]]\n",
      "40 cost: 671821.4 \n",
      "hf:\n",
      " [[1.0307889 ]\n",
      " [0.61479414]\n",
      " [0.9012821 ]\n",
      " [1.2680299 ]\n",
      " [1.0487196 ]\n",
      " [1.1773853 ]\n",
      " [1.3351234 ]\n",
      " [1.4734871 ]]\n",
      "41 cost: 671816.5 \n",
      "hf:\n",
      " [[1.034742  ]\n",
      " [0.61870015]\n",
      " [0.9045626 ]\n",
      " [1.2706047 ]\n",
      " [1.0517353 ]\n",
      " [1.1803063 ]\n",
      " [1.3371634 ]\n",
      " [1.4755139 ]]\n",
      "42 cost: 671811.6 \n",
      "hf:\n",
      " [[1.0386951 ]\n",
      " [0.62260616]\n",
      " [0.9078432 ]\n",
      " [1.2731794 ]\n",
      " [1.0547509 ]\n",
      " [1.1832273 ]\n",
      " [1.3392035 ]\n",
      " [1.4775405 ]]\n",
      "43 cost: 671806.75 \n",
      "hf:\n",
      " [[1.0426482 ]\n",
      " [0.62651217]\n",
      " [0.91112375]\n",
      " [1.2757542 ]\n",
      " [1.0577666 ]\n",
      " [1.1861485 ]\n",
      " [1.3412435 ]\n",
      " [1.4795672 ]]\n",
      "44 cost: 671801.9 \n",
      "hf:\n",
      " [[1.0466013]\n",
      " [0.6304183]\n",
      " [0.9144044]\n",
      " [1.2783289]\n",
      " [1.0607822]\n",
      " [1.1890695]\n",
      " [1.3432835]\n",
      " [1.4815938]]\n",
      "45 cost: 671797.0 \n",
      "hf:\n",
      " [[1.0505544]\n",
      " [0.6343243]\n",
      " [0.9176849]\n",
      " [1.2809036]\n",
      " [1.0637978]\n",
      " [1.1919906]\n",
      " [1.3453236]\n",
      " [1.4836205]]\n",
      "46 cost: 671792.1 \n",
      "hf:\n",
      " [[1.0545075 ]\n",
      " [0.6382303 ]\n",
      " [0.92096555]\n",
      " [1.2834783 ]\n",
      " [1.0668135 ]\n",
      " [1.1949117 ]\n",
      " [1.3473636 ]\n",
      " [1.4856472 ]]\n",
      "47 cost: 671787.25 \n",
      "hf:\n",
      " [[1.0584606 ]\n",
      " [0.64213645]\n",
      " [0.92424613]\n",
      " [1.286053  ]\n",
      " [1.069829  ]\n",
      " [1.1978328 ]\n",
      " [1.3494036 ]\n",
      " [1.4876739 ]]\n",
      "48 cost: 671782.4 \n",
      "hf:\n",
      " [[1.0624137 ]\n",
      " [0.64604247]\n",
      " [0.9275267 ]\n",
      " [1.2886277 ]\n",
      " [1.0728446 ]\n",
      " [1.2007539 ]\n",
      " [1.3514438 ]\n",
      " [1.4897006 ]]\n",
      "49 cost: 671777.56 \n",
      "hf:\n",
      " [[1.0663667 ]\n",
      " [0.64994836]\n",
      " [0.93080723]\n",
      " [1.2912024 ]\n",
      " [1.0758601 ]\n",
      " [1.2036748 ]\n",
      " [1.3534837 ]\n",
      " [1.4917272 ]]\n",
      "50 cost: 671772.6 \n",
      "hf:\n",
      " [[1.0703194 ]\n",
      " [0.65385425]\n",
      " [0.93408763]\n",
      " [1.293777  ]\n",
      " [1.0788755 ]\n",
      " [1.2065957 ]\n",
      " [1.3555236 ]\n",
      " [1.4937538 ]]\n",
      "51 cost: 671767.8 \n",
      "hf:\n",
      " [[1.0742723]\n",
      " [0.6577599]\n",
      " [0.9373679]\n",
      " [1.2963514]\n",
      " [1.0818911]\n",
      " [1.2095165]\n",
      " [1.3575635]\n",
      " [1.4957802]]\n",
      "52 cost: 671762.9 \n",
      "hf:\n",
      " [[1.0782251]\n",
      " [0.6616657]\n",
      " [0.9406483]\n",
      " [1.298926 ]\n",
      " [1.0849063]\n",
      " [1.2124375]\n",
      " [1.3596034]\n",
      " [1.4978068]]\n",
      "53 cost: 671758.06 \n",
      "hf:\n",
      " [[1.0821779 ]\n",
      " [0.66557133]\n",
      " [0.9439287 ]\n",
      " [1.3015006 ]\n",
      " [1.0879217 ]\n",
      " [1.2153584 ]\n",
      " [1.3616433 ]\n",
      " [1.4998333 ]]\n",
      "54 cost: 671753.25 \n",
      "hf:\n",
      " [[1.0861309]\n",
      " [0.6694771]\n",
      " [0.947209 ]\n",
      " [1.304075 ]\n",
      " [1.0909371]\n",
      " [1.2182792]\n",
      " [1.3636831]\n",
      " [1.5018599]]\n",
      "55 cost: 671748.3 \n",
      "hf:\n",
      " [[1.0900836]\n",
      " [0.6733829]\n",
      " [0.9504893]\n",
      " [1.3066496]\n",
      " [1.0939527]\n",
      " [1.2212   ]\n",
      " [1.365723 ]\n",
      " [1.5038863]]\n",
      "56 cost: 671743.5 \n",
      "hf:\n",
      " [[1.0940363 ]\n",
      " [0.67728865]\n",
      " [0.9537697 ]\n",
      " [1.3092241 ]\n",
      " [1.0969679 ]\n",
      " [1.224121  ]\n",
      " [1.3677628 ]\n",
      " [1.5059129 ]]\n",
      "57 cost: 671738.56 \n",
      "hf:\n",
      " [[1.0979892 ]\n",
      " [0.6811944 ]\n",
      " [0.95704997]\n",
      " [1.3117986 ]\n",
      " [1.0999835 ]\n",
      " [1.2270418 ]\n",
      " [1.3698027 ]\n",
      " [1.5079395 ]]\n",
      "58 cost: 671733.75 \n",
      "hf:\n",
      " [[1.1019421]\n",
      " [0.6851001]\n",
      " [0.9603303]\n",
      " [1.3143731]\n",
      " [1.1029987]\n",
      " [1.2299626]\n",
      " [1.3718426]\n",
      " [1.5099659]]\n",
      "59 cost: 671728.9 \n",
      "hf:\n",
      " [[1.1058948 ]\n",
      " [0.68900585]\n",
      " [0.96361065]\n",
      " [1.3169477 ]\n",
      " [1.1060141 ]\n",
      " [1.2328835 ]\n",
      " [1.3738825 ]\n",
      " [1.5119925 ]]\n",
      "60 cost: 671724.0 \n",
      "hf:\n",
      " [[1.1098475 ]\n",
      " [0.6929115 ]\n",
      " [0.96689093]\n",
      " [1.3195221 ]\n",
      " [1.1090295 ]\n",
      " [1.2358043 ]\n",
      " [1.3759223 ]\n",
      " [1.514019  ]]\n",
      "61 cost: 671719.1 \n",
      "hf:\n",
      " [[1.1138003 ]\n",
      " [0.6968173 ]\n",
      " [0.97017133]\n",
      " [1.3220967 ]\n",
      " [1.1120448 ]\n",
      " [1.2387252 ]\n",
      " [1.3779622 ]\n",
      " [1.5160455 ]]\n",
      "62 cost: 671714.25 \n",
      "hf:\n",
      " [[1.117753  ]\n",
      " [0.70072293]\n",
      " [0.9734516 ]\n",
      " [1.3246711 ]\n",
      " [1.1150601 ]\n",
      " [1.241646  ]\n",
      " [1.380002  ]\n",
      " [1.518072  ]]\n",
      "63 cost: 671709.4 \n",
      "hf:\n",
      " [[1.1217058]\n",
      " [0.7046286]\n",
      " [0.9767319]\n",
      " [1.3272457]\n",
      " [1.1180755]\n",
      " [1.2445668]\n",
      " [1.3820419]\n",
      " [1.5200984]]\n",
      "64 cost: 671704.5 \n",
      "hf:\n",
      " [[1.1256585 ]\n",
      " [0.70853436]\n",
      " [0.9800122 ]\n",
      " [1.3298202 ]\n",
      " [1.1210909 ]\n",
      " [1.2474877 ]\n",
      " [1.3840818 ]\n",
      " [1.522125  ]]\n",
      "65 cost: 671699.6 \n",
      "hf:\n",
      " [[1.1296113 ]\n",
      " [0.7124399 ]\n",
      " [0.98329246]\n",
      " [1.3323947 ]\n",
      " [1.1241063 ]\n",
      " [1.2504085 ]\n",
      " [1.3861217 ]\n",
      " [1.5241516 ]]\n",
      "66 cost: 671694.75 \n",
      "hf:\n",
      " [[1.133564  ]\n",
      " [0.71634567]\n",
      " [0.98657274]\n",
      " [1.3349692 ]\n",
      " [1.1271217 ]\n",
      " [1.2533293 ]\n",
      " [1.3881617 ]\n",
      " [1.5261781 ]]\n",
      "67 cost: 671689.9 \n",
      "hf:\n",
      " [[1.1375167 ]\n",
      " [0.72025144]\n",
      " [0.989853  ]\n",
      " [1.3375437 ]\n",
      " [1.130137  ]\n",
      " [1.2562501 ]\n",
      " [1.3902014 ]\n",
      " [1.5282046 ]]\n",
      "68 cost: 671685.0 \n",
      "hf:\n",
      " [[1.1414695 ]\n",
      " [0.724157  ]\n",
      " [0.99313337]\n",
      " [1.3401182 ]\n",
      " [1.1331522 ]\n",
      " [1.2591709 ]\n",
      " [1.3922414 ]\n",
      " [1.530231  ]]\n",
      "69 cost: 671680.1 \n",
      "hf:\n",
      " [[1.1454222 ]\n",
      " [0.72806275]\n",
      " [0.99641365]\n",
      " [1.3426926 ]\n",
      " [1.1361676 ]\n",
      " [1.2620918 ]\n",
      " [1.3942811 ]\n",
      " [1.5322576 ]]\n",
      "70 cost: 671675.3 \n",
      "hf:\n",
      " [[1.1493747 ]\n",
      " [0.73196816]\n",
      " [0.9996938 ]\n",
      " [1.345267  ]\n",
      " [1.1391828 ]\n",
      " [1.2650125 ]\n",
      " [1.3963209 ]\n",
      " [1.534284  ]]\n",
      "71 cost: 671670.4 \n",
      "hf:\n",
      " [[1.1533273]\n",
      " [0.7358738]\n",
      " [1.002974 ]\n",
      " [1.3478414]\n",
      " [1.1421981]\n",
      " [1.2679331]\n",
      " [1.3983607]\n",
      " [1.5363104]]\n",
      "72 cost: 671665.56 \n",
      "hf:\n",
      " [[1.15728   ]\n",
      " [0.73977923]\n",
      " [1.0062541 ]\n",
      " [1.3504157 ]\n",
      " [1.1452134 ]\n",
      " [1.2708538 ]\n",
      " [1.4004004 ]\n",
      " [1.5383368 ]]\n",
      "73 cost: 671660.7 \n",
      "hf:\n",
      " [[1.1612325]\n",
      " [0.7436849]\n",
      " [1.0095342]\n",
      " [1.3529902]\n",
      " [1.1482285]\n",
      " [1.2737746]\n",
      " [1.4024402]\n",
      " [1.5403632]]\n",
      "74 cost: 671655.8 \n",
      "hf:\n",
      " [[1.1651851]\n",
      " [0.7475904]\n",
      " [1.0128144]\n",
      " [1.3555645]\n",
      " [1.1512437]\n",
      " [1.2766953]\n",
      " [1.40448  ]\n",
      " [1.5423896]]\n",
      "75 cost: 671650.94 \n",
      "hf:\n",
      " [[1.1691377 ]\n",
      " [0.75149596]\n",
      " [1.0160946 ]\n",
      " [1.3581389 ]\n",
      " [1.154259  ]\n",
      " [1.2796159 ]\n",
      " [1.4065197 ]\n",
      " [1.544416  ]]\n",
      "76 cost: 671646.1 \n",
      "hf:\n",
      " [[1.1730902]\n",
      " [0.7554015]\n",
      " [1.0193747]\n",
      " [1.3607132]\n",
      " [1.1572741]\n",
      " [1.2825365]\n",
      " [1.4085594]\n",
      " [1.5464424]]\n",
      "77 cost: 671641.25 \n",
      "hf:\n",
      " [[1.1770428]\n",
      " [0.7593069]\n",
      " [1.0226549]\n",
      " [1.3632877]\n",
      " [1.1602894]\n",
      " [1.2854574]\n",
      " [1.4105992]\n",
      " [1.5484687]]\n",
      "78 cost: 671636.4 \n",
      "hf:\n",
      " [[1.1809955 ]\n",
      " [0.76321244]\n",
      " [1.0259349 ]\n",
      " [1.365862  ]\n",
      " [1.1633046 ]\n",
      " [1.2883779 ]\n",
      " [1.4126389 ]\n",
      " [1.5504951 ]]\n",
      "79 cost: 671631.5 \n",
      "hf:\n",
      " [[1.184948  ]\n",
      " [0.76711786]\n",
      " [1.0292151 ]\n",
      " [1.3684363 ]\n",
      " [1.1663198 ]\n",
      " [1.2912986 ]\n",
      " [1.4146787 ]\n",
      " [1.5525215 ]]\n",
      "80 cost: 671626.6 \n",
      "hf:\n",
      " [[1.1889005]\n",
      " [0.7710233]\n",
      " [1.0324953]\n",
      " [1.3710107]\n",
      " [1.1693349]\n",
      " [1.2942193]\n",
      " [1.4167184]\n",
      " [1.5545478]]\n",
      "81 cost: 671621.75 \n",
      "hf:\n",
      " [[1.192853 ]\n",
      " [0.7749287]\n",
      " [1.0357753]\n",
      " [1.373585 ]\n",
      " [1.17235  ]\n",
      " [1.2971399]\n",
      " [1.4187582]\n",
      " [1.5565741]]\n",
      "82 cost: 671616.9 \n",
      "hf:\n",
      " [[1.1968055]\n",
      " [0.7788341]\n",
      " [1.0390553]\n",
      " [1.3761593]\n",
      " [1.1753652]\n",
      " [1.3000605]\n",
      " [1.4207978]\n",
      " [1.5586005]]\n",
      "83 cost: 671612.0 \n",
      "hf:\n",
      " [[1.200758  ]\n",
      " [0.78273964]\n",
      " [1.0423355 ]\n",
      " [1.3787336 ]\n",
      " [1.1783805 ]\n",
      " [1.3029811 ]\n",
      " [1.4228376 ]\n",
      " [1.5606269 ]]\n",
      "84 cost: 671607.2 \n",
      "hf:\n",
      " [[1.2047104 ]\n",
      " [0.78664494]\n",
      " [1.0456154 ]\n",
      " [1.381308  ]\n",
      " [1.1813955 ]\n",
      " [1.3059016 ]\n",
      " [1.4248773 ]\n",
      " [1.5626533 ]]\n",
      "85 cost: 671602.25 \n",
      "hf:\n",
      " [[1.2086627 ]\n",
      " [0.79055023]\n",
      " [1.0488955 ]\n",
      " [1.3838822 ]\n",
      " [1.1844106 ]\n",
      " [1.3088222 ]\n",
      " [1.4269171 ]\n",
      " [1.5646796 ]]\n",
      "86 cost: 671597.4 \n",
      "hf:\n",
      " [[1.212615 ]\n",
      " [0.7944555]\n",
      " [1.0521755]\n",
      " [1.3864565]\n",
      " [1.1874257]\n",
      " [1.3117428]\n",
      " [1.4289567]\n",
      " [1.566706 ]]\n",
      "87 cost: 671592.56 \n",
      "hf:\n",
      " [[1.2165675]\n",
      " [0.7983608]\n",
      " [1.0554554]\n",
      " [1.3890308]\n",
      " [1.1904407]\n",
      " [1.3146634]\n",
      " [1.4309964]\n",
      " [1.5687323]]\n",
      "88 cost: 671587.7 \n",
      "hf:\n",
      " [[1.2205198 ]\n",
      " [0.80226624]\n",
      " [1.0587355 ]\n",
      " [1.391605  ]\n",
      " [1.1934558 ]\n",
      " [1.3175839 ]\n",
      " [1.4330361 ]\n",
      " [1.5707587 ]]\n",
      "89 cost: 671582.9 \n",
      "hf:\n",
      " [[1.2244722 ]\n",
      " [0.80617154]\n",
      " [1.0620154 ]\n",
      " [1.3941793 ]\n",
      " [1.1964709 ]\n",
      " [1.3205045 ]\n",
      " [1.4350759 ]\n",
      " [1.572785  ]]\n",
      "90 cost: 671577.94 \n",
      "hf:\n",
      " [[1.2284243]\n",
      " [0.8100767]\n",
      " [1.0652953]\n",
      " [1.3967534]\n",
      " [1.1994859]\n",
      " [1.323425 ]\n",
      " [1.4371154]\n",
      " [1.5748112]]\n",
      "91 cost: 671573.0 \n",
      "hf:\n",
      " [[1.2323766]\n",
      " [0.8139819]\n",
      " [1.0685753]\n",
      " [1.3993276]\n",
      " [1.2025008]\n",
      " [1.3263454]\n",
      " [1.4391551]\n",
      " [1.5768375]]\n",
      "92 cost: 671568.2 \n",
      "hf:\n",
      " [[1.2363288 ]\n",
      " [0.81788707]\n",
      " [1.0718551 ]\n",
      " [1.4019017 ]\n",
      " [1.2055159 ]\n",
      " [1.3292658 ]\n",
      " [1.4411945 ]\n",
      " [1.5788637 ]]\n",
      "93 cost: 671563.4 \n",
      "hf:\n",
      " [[1.2402811 ]\n",
      " [0.82179224]\n",
      " [1.075135  ]\n",
      " [1.4044759 ]\n",
      " [1.2085307 ]\n",
      " [1.3321862 ]\n",
      " [1.4432342 ]\n",
      " [1.5808899 ]]\n",
      "94 cost: 671558.5 \n",
      "hf:\n",
      " [[1.2442334 ]\n",
      " [0.82569754]\n",
      " [1.0784149 ]\n",
      " [1.4070501 ]\n",
      " [1.2115457 ]\n",
      " [1.3351067 ]\n",
      " [1.4452738 ]\n",
      " [1.5829163 ]]\n",
      "95 cost: 671553.6 \n",
      "hf:\n",
      " [[1.2481855]\n",
      " [0.8296026]\n",
      " [1.0816947]\n",
      " [1.4096242]\n",
      " [1.2145606]\n",
      " [1.3380271]\n",
      " [1.4473133]\n",
      " [1.5849425]]\n",
      "96 cost: 671548.75 \n",
      "hf:\n",
      " [[1.2521377]\n",
      " [0.8335079]\n",
      " [1.0849745]\n",
      " [1.4121983]\n",
      " [1.2175756]\n",
      " [1.3409476]\n",
      " [1.449353 ]\n",
      " [1.5869687]]\n",
      "97 cost: 671543.9 \n",
      "hf:\n",
      " [[1.2560899]\n",
      " [0.8374131]\n",
      " [1.0882545]\n",
      " [1.4147725]\n",
      " [1.2205906]\n",
      " [1.343868 ]\n",
      " [1.4513925]\n",
      " [1.588995 ]]\n",
      "98 cost: 671539.0 \n",
      "hf:\n",
      " [[1.2600422 ]\n",
      " [0.84131825]\n",
      " [1.0915344 ]\n",
      " [1.4173466 ]\n",
      " [1.2236054 ]\n",
      " [1.3467884 ]\n",
      " [1.4534321 ]\n",
      " [1.5910212 ]]\n",
      "99 cost: 671534.1 \n",
      "hf:\n",
      " [[1.2639943]\n",
      " [0.8452234]\n",
      " [1.0948142]\n",
      " [1.4199208]\n",
      " [1.2266204]\n",
      " [1.3497088]\n",
      " [1.4554718]\n",
      " [1.5930474]]\n",
      "100 cost: 671529.25 \n",
      "hf:\n",
      " [[1.2679465]\n",
      " [0.8491286]\n",
      " [1.098094 ]\n",
      " [1.4224949]\n",
      " [1.2296354]\n",
      " [1.3526293]\n",
      " [1.4575113]\n",
      " [1.5950737]]\n"
     ]
    }
   ],
   "source": [
    "train = tf.train.GradientDescentOptimizer(1e-6).minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(101):\n",
    "    cv, hv,_ = sess.run([cost, hf, train], feed_dict={x: xdata, y: ydata})\n",
    "    print(step, \"cost:\", cv, \"\\nhf:\\n\", hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "#y값은 one hot 인코딩 방식으로 초기화 함\n",
    "y_data = [[0, 0, 1],#2\n",
    "          [0, 0, 1],#2\n",
    "          [0, 0, 1],#2\n",
    "          [0, 1, 0],#1\n",
    "          [0, 1, 0],#1\n",
    "          [0, 1, 0],#1\n",
    "          [1, 0, 0],#0\n",
    "          [1, 0, 0]]#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "x = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "w = tf.Variable(tf.random_normal([4, num_classes]))\n",
    "b = tf.Variable(tf.random_normal([num_classes]))\n",
    "# [None, 4] + [4, 3] + [3] = [None, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4589431\n",
      "200 0.6289947\n",
      "400 0.5186465\n",
      "600 0.4247184\n",
      "800 0.33368528\n",
      "1000 0.24964908\n",
      "1200 0.22058901\n",
      "1400 0.20100299\n",
      "1600 0.18450218\n",
      "1800 0.17041746\n",
      "2000 0.15826182\n",
      "==================================================\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(train, feed_dict={x: x_data, y: y_data})\n",
    "        if step%200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={x: x_data, y: y_data}))\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "#     print(sess.run(hf, feed_dict={x: np.array([1, 11, 7, 9]).reshape(-1, 4)}))\n",
    "    res = sess.run(hf, feed_dict={x: [[1, 11, 7, 9],\n",
    "                                      [1, 3, 4, 3],\n",
    "                                      [1, 1, 0, 1]]})\n",
    "    print(sess.run(tf.argmax(res, axis=1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Zoo](http://archive.ics.uci.edu/ml/datasets/Zoo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 3.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 6.],\n",
       "       [0., 1., 1., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt(\"./res/zoo/zoo.csv\", delimiter=\",\", dtype=np.float32)\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 17)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16)\n",
      "(101, 1)\n"
     ]
    }
   ],
   "source": [
    "xdata = xy[:, 0:-1]\n",
    "ydata = xy[:, [-1]]\n",
    "print(xdata.shape)\n",
    "print(ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot_4:0\", shape=(?, 1, 7), dtype=float32)\n",
      "one_hot after reshape Tensor(\"Reshape_4:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 16])\n",
    "y = tf.placeholder(tf.int64, [None, 1]) # float type이면 one-hot encoding을 할 수 없음\n",
    "# one-hot encoding을 할 데이터, class 개수 3(y) → 0001000(7일 때)\n",
    "y_one_hot = tf.one_hot(y, 7) \n",
    "print(\"one_hot\", y_one_hot)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, 7])\n",
    "print(\"one_hot after reshape\", y_one_hot)\n",
    "# one hot 함수는 한 차원 높게 변환된다\n",
    "# y [[0], [3], ..., [5]] \n",
    "# → one_hot \n",
    "# → [[[1000000]], [[0001000]], ..., [[0000010]]] → 최종 shape [None, 1, 7]\n",
    "# 바라는 출력 결과의 모습 → [None, 7]\n",
    "# reshape을 사용 tf.shape(y_one_hot, [-1, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([16, 7]))\n",
    "b = tf.Variable(tf.random_normal([7]))\n",
    "\n",
    "logit = tf.matmul(x, w)+b\n",
    "hf = tf.nn.softmax(logit) \n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, \n",
    "                                                labels=y_one_hot)\n",
    "cost2 = tf.reduce_mean(cost)\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost2)\n",
    "prediction = tf.argmax(hf, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 cost:  10.13701 acc:  0.00990099\n",
      "step 1000 cost:  0.102877945 acc:  1.0\n",
      "step 2000 cost:  0.055003304 acc:  1.0\n",
      "step 3000 cost:  0.037782468 acc:  1.0\n",
      "step 4000 cost:  0.028867332 acc:  1.0\n",
      "step 5000 cost:  0.023400003 acc:  1.0\n",
      "step 6000 cost:  0.019695893 acc:  1.0\n",
      "step 7000 cost:  0.017016307 acc:  1.0\n",
      "step 8000 cost:  0.01498566 acc:  1.0\n",
      "step 9000 cost:  0.013392487 acc:  1.0\n",
      "step 10000 cost:  0.01210847 acc:  1.0\n",
      "[0 0 3 0 0 0 0 3 3 0 0 1 3 6 6 6 1 0 3 0 1 1 0 1 5 4 4 0 0 0 5 0 0 1 3 0 0\n",
      " 1 3 5 5 1 5 1 0 0 6 0 0 0 0 5 4 6 0 0 1 1 1 1 3 3 2 0 0 0 0 0 0 0 0 1 6 3\n",
      " 0 0 2 6 1 1 2 6 3 1 0 6 3 1 5 4 2 2 3 0 0 1 0 5 0 6 1]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x: xdata, y: ydata})\n",
    "        if step%1000 == 0:\n",
    "            cv, av = sess.run([cost2, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "            print(\"step\", step, \"cost: \", cv, \"acc: \", av)\n",
    "# 전체 데이터로 트레이닝 수행하여 모델 생성\n",
    "# 모델에 전체 데이터를 집어 넣어서 정확도 출력\n",
    "# 데이터 분할하지 않음\n",
    "    pred = sess.run(prediction, feed_dict={x: xdata})\n",
    "    print(pred) # 예측한 데이터 class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten()\n",
    "차원을 내려주는 함수\n",
    "[[1], [0]] → [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 cost:  6.2248654 acc:  0.04950495\n",
      "step 1000 cost:  0.10257621 acc:  0.990099\n",
      "step 2000 cost:  0.05318573 acc:  1.0\n",
      "step 3000 cost:  0.03637441 acc:  1.0\n",
      "step 4000 cost:  0.027794149 acc:  1.0\n",
      "step 5000 cost:  0.022555783 acc:  1.0\n",
      "step 6000 cost:  0.019012952 acc:  1.0\n",
      "step 7000 cost:  0.01645145 acc:  1.0\n",
      "step 8000 cost:  0.014510152 acc:  1.0\n",
      "step 9000 cost:  0.012986445 acc:  1.0\n",
      "step 10000 cost:  0.011757602 acc:  1.0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 4 실제 y 4\n",
      "[True] 예측 4 실제 y 4\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 4 실제 y 4\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 2 실제 y 2\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 2 실제 y 2\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 2 실제 y 2\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 4 실제 y 4\n",
      "[True] 예측 2 실제 y 2\n",
      "[True] 예측 2 실제 y 2\n",
      "[True] 예측 3 실제 y 3\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 1 실제 y 1\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 5 실제 y 5\n",
      "[True] 예측 0 실제 y 0\n",
      "[True] 예측 6 실제 y 6\n",
      "[True] 예측 1 실제 y 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x: xdata, y: ydata})\n",
    "        if step%1000 == 0:\n",
    "            cv, av = sess.run([cost2, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "            print(\"step\", step, \"cost: \", cv, \"acc: \", av)\n",
    "    pred = sess.run(prediction, feed_dict={x: xdata})\n",
    "    for p, y in zip(pred, ydata.flatten()):\n",
    "        print(\"[{}] 예측 {} 실제 y {}\".format(p==int(y), p, int(y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
